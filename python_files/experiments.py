# -*- coding: utf-8 -*-
"""Braining_Mini_Challenge_Tests.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16uMD4kTXlLvcqXHsBi3UYatAdniaHIa6

### Test Notebook for Predicting Stroke Risk Based on Lifestyle Habits Project
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, recall_score, precision_score
from sklearn.utils import resample
from imblearn.over_sampling import RandomOverSampler, SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.model_selection import cross_val_score, StratifiedKFold

"""#### Inspect data and calculate statistical variables"""

stroke_data = pd.read_csv("/content/I05-0006 stroke_risk.csv")
stroke_data.head()

stroke_data.info()

stroke_data.describe()

stroke_data.isnull().sum()

"""### Data Preprocessing"""

# Function to detect outliers in a numerical column
def detect_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
    print(f"\nOutliers in {column}:")
    print(outliers[[column]])

    return lower_bound, upper_bound

# Checkk for outliers in bmi and sleep_hours (shown originally in EDA)
bmi_lower, bmi_upper = detect_outliers_iqr(stroke_data, "bmi")
sleep_lower, sleep_upper = detect_outliers_iqr(stroke_data, "sleep_hours")

# Function to cap outliers
def cap_outliers(df, column, lower_bound, upper_bound):
    df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)
    return df

# cap outliers in bmi and sleep_hours- winsorization
stroke_data = cap_outliers(stroke_data, "bmi", bmi_lower, bmi_upper)
stroke_data = cap_outliers(stroke_data, "sleep_hours", sleep_lower, sleep_upper)

"""### Feature Engineering"""

# Add variable to account for age class (below or above 50)
bins = [30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]
labels = ["30–34", "35-39", "40–44", "45-49", "50–54", "55-59", "60–64", "65-69", "70–74", "75-79"]
stroke_data["age_group"] = pd.cut(stroke_data["age"], bins=bins, labels=labels, right=False)
stroke_data.head()

# Plot of stroke risk by age class
age_stroke_counts = stroke_data.groupby(["age_group", "stroke_risk"], observed=True).size().reset_index(name="count")
plt.figure(figsize=(8,6))
sns.barplot(data=age_stroke_counts, x="age_group", y="count", hue="stroke_risk")

plt.title("Stroke Distribution Across Age Groups")
plt.xlabel("Age Group")
plt.ylabel("Number of Patients")
plt.legend(title="Stroke Risk")
plt.show()

age_stroke_pivot = stroke_data.pivot_table(index="age_group", columns="stroke_risk", values="exercise_frequency",
                                          aggfunc='count',fill_value=0, observed=True)

print(age_stroke_pivot)

# Plot to understand the trend in exercise level and age by stroke risk class
g = sns.catplot(data=stroke_data, x="age_group", hue="stroke_risk", col="exercise_frequency",
            kind="count", height=4,aspect=1)
for ax in g.axes.flatten():
    ax.tick_params(axis='x', rotation=90)
plt.subplots_adjust(top=0.8)
plt.suptitle("Stroke Risk by Age Group and Exercise Frequency")
plt.show()

# Get unique values from categorical columns
def get_unique_cat(data, col):
  return data[col].unique()

# Get unique values in categorical columns ahead of encoding
categorical_cols = ["smoking_status", "exercise_frequency", "stroke_risk"]
for i in categorical_cols:
  print(f"Unique values in {i}: {get_unique_cat(stroke_data, i)}")

# Mapping for encoding categorical columns
cat_cols = ["exercise_frequency", "stroke_risk"]
exercise_frequency_map = {"High":0, "Low":2, "Moderate":1}
stroke_risk_map = {"No":0, "Yes":1}
maps = [exercise_frequency_map, stroke_risk_map]

# Function to perform ordinal encoding on categorical variables
def ordinal_encoding(data, columns, maps):
  data = data.copy()
  for col, mapping in zip(columns, maps):
    data[col] = data[col].map(mapping)
  return data

# Confirm ordinal encoding
stroke_df = ordinal_encoding(stroke_data, cat_cols, maps)
for i in cat_cols:
  print(f"Unique values in {i}: {get_unique_cat(stroke_df, i)}")

# One hot encoding for the smoking status column
stroke_df = pd.get_dummies(stroke_df, columns=["smoking_status"], drop_first=True, dtype=int)

# New variables to account for variable interactions
stroke_df["age_above_50"] = (stroke_df["age"] > 50).astype(int) + 1
stroke_df["exercise_x_age"] = stroke_df["exercise_frequency"] * stroke_df["age"]
stroke_df["exercise_x_bmi"] = stroke_df["exercise_frequency"] * stroke_df["bmi"]
stroke_df["exercise_bmi_50"] = stroke_df["exercise_frequency"] * stroke_df["bmi"] * stroke_df["age_above_50"]
stroke_df["sleep_hours"] = stroke_df["sleep_hours"] * stroke_df["exercise_frequency"]

# Square the age variable to capture non-linearities
stroke_df["age_squared"] = stroke_df["age"] ** 2

# Function to classify bmi
def classify_bmi(bmi):
    if bmi < 18.5:
        return 1
    elif 18.5 <= bmi < 25:
        return 2
    elif 25 <= bmi < 30:
        return 3
    elif 30 <= bmi < 35:
        return 4
    elif 35 <= bmi < 40:
        return 5
    else:
        return 6

stroke_df["bmi_class"] = stroke_df["bmi"].apply(classify_bmi)

stroke_df["bmi_class"].value_counts()

# Drop rows with stroke class 5
stroke_df = stroke_df[~stroke_df['bmi_class'].isin([5])].reset_index(drop=True)

stroke_df["bmi_class"].value_counts()

# Add weighting to bmi variable
stroke_df["bmi_weighted"] = stroke_df["bmi"] * stroke_df["bmi_class"]

# Round sleep hours to whole number
stroke_df["sleep_rounded"] = stroke_df["sleep_hours"].round()

stroke_df.head()

"""#### Checking for class imbalance in the target variable"""

# Value count for target variable to check for class imbalance
class_counts = stroke_df['stroke_risk'].value_counts()
print("Number of samples per class:")
print(class_counts)

plt.rcParams['figure.figsize'] = (8, 6)

# Visualizing class imbalance
sns.countplot(x='stroke_risk', data=stroke_df, hue="stroke_risk", palette=["gray","red"])
plt.title("Stroke Risk Class Distribution")
plt.xlabel("Stroke Risk")
plt.ylabel("Frequency")
plt.show()

"""#### Checking for collinearity"""

# Confusion matrix to check for collinearity
corr = stroke_df.corr(numeric_only=True)
sns.heatmap(corr, annot=True, fmt=".2f", cmap="Reds", square=True, cbar=True)
plt.title("Correlation Heatmap of Stroke Dataset Variables")
plt.show()

# Print total columns in dataset
stroke_df.columns

# Split features and target variable, drop collinear columns
X = stroke_df.drop(["stroke_risk", "age_group", "age", "age_above_50", "bmi", "sleep_hours"], axis=1)
y = stroke_df["stroke_risk"]

"""#### Dealing with class imbalance"""

# Oversampling minority class to 200
smote = SMOTE(sampling_strategy={1: 200}, random_state=42)
X_smote, y_smote = smote.fit_resample(X,y)

# Undersampling majority class to 200
undersample = RandomUnderSampler(random_state=7)
X_under, y_under = undersample.fit_resample(X_smote, y_smote)

# Ensure that target classes are now balanced
class_counts = y_under.value_counts()
print("Number of samples per class:")
print(class_counts)

"""### Model training and evaluation"""

# Data splitting
X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Grid search parameters
penalty = ['l1', 'l2', 'elasticnet']
c_values = [100, 10, 1.0, 0.1, 0.01]
solver = ["newton-cg", "lbfgs", "liblinear", "sag", "saga"]
max_iter= [100, 1000, 2500, 5000,10000, 20000]

# Create dictionary of parameters for grid search
params = dict(penalty = penalty, C = c_values, solver = solver)
startified_kfold_cv = StratifiedKFold(n_splits=3, shuffle=False)

# Instantiate logistic regressor
lr = LogisticRegression()

# Perform grid search
grid_search = GridSearchCV(estimator = lr, param_grid = params, scoring = 'accuracy', cv = startified_kfold_cv)
grid_search = grid_search.fit(X_train, y_train)

# Print best grid search parameters
grid_search.best_params_, grid_search.best_score_

# Make predictions
y_pred = grid_search.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)
print("Accuracy: {:.2f}%".format(accuracy * 100))
print("Confusion Matrix:\n", confusion_mat)
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Plot confusion matrix
sns.heatmap(confusion_mat, annot=True, fmt="d", cmap="Blues", xticklabels=["No","Yes"], yticklabels=["No","Yes"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

# ROC curve
y_prob = grid_search.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2,
         label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve\nAccuracy: {:.2f}%'.format(
    accuracy * 100))
plt.legend(loc="lower right")
plt.show()

"""#### Testing different data split ratios"""

# Test different split ratios
split_ratios = [0.7, 0.75, 0.8, 0.85]
accuracy_list = []
recall_list = []
precision_list = []

# Train model with different split ratios
for test_size in [1 - ratio for ratio in split_ratios]:
    X_trainn, X_testt, y_trainn, y_testt = train_test_split(X_under, y_under, test_size=test_size, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_trainn)
    X_test_scaled = scaler.transform(X_testt)
    model = LogisticRegression(C=1, penalty = "l1", solver = "saga", max_iter=5000)
    model.fit(X_train_scaled, y_trainn)

    y_predd = model.predict(X_test_scaled)

    accuracy_list.append(accuracy_score(y_testt, y_predd))
    recall_list.append(recall_score(y_testt, y_predd))
    precision_list.append(precision_score(y_testt, y_predd))

# Plot results
plt.figure(figsize=(8,6))
plt.plot(split_ratios, accuracy_list, marker="o", label="Accuracy")
plt.plot(split_ratios, recall_list, marker="o", label="Recall (Class 1)")
plt.plot(split_ratios, precision_list, marker="o", label="Precision (Class 1)")

plt.title("Model Performance Across Different Train-Test Splits")
plt.xlabel("Training Set Ratio")
plt.ylabel("Score")
plt.ylim(0, 1)
plt.legend()
plt.grid(True)
plt.show()

print("Accuracy:", accuracy_list)
print("Recall:", recall_list)
print("Precision:", precision_list)

